{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython2",
  "version": 2,
  "kernelspec": {
   "name": "python37564bitpysparkvenvvenv12caecce4d7944089893a0cc0cfe69ee",
   "display_name": "Python 3.7.5 64-bit ('pyspark_venv': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.context import SQLContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "    \n",
    "sc = SparkContext()\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<re.Match object; span=(0, 25), match=\"I'm searching for a spark\"> 0 25\n<re.Match object; span=(25, 36), match=' in PySpark'> 25 36\n"
    }
   ],
   "source": [
    "m = re.finditer(r'.*?(spark).*?', \"I'm searching for a spark in PySpark\", re.I)\n",
    "for match in m:\n",
    "    print(match, match.start(), match.end())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data\n",
    "1) Download it if they do not exist locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "--2020-04-15 15:12:59--  ftp://ita.ee.lbl.gov/traces/clarknet_access_log_Aug28.gz\n           => ‘clarknet_access_log_Aug28.gz’\nResolving ita.ee.lbl.gov (ita.ee.lbl.gov)... 131.243.2.164\nConnecting to ita.ee.lbl.gov (ita.ee.lbl.gov)|131.243.2.164|:21... connected.\nLogging in as anonymous ...\nLogin incorrect.\nmv: rename ./clarknet_access_log_Aug28.gz to ./data/clarknet_access_log_Aug28.gz: No such file or directory\n--2020-04-15 15:12:59--  ftp://ita.ee.lbl.gov/traces/clarknet_access_log_Sep4.gz\n           => ‘clarknet_access_log_Sep4.gz’\nResolving ita.ee.lbl.gov (ita.ee.lbl.gov)... 131.243.2.164\nConnecting to ita.ee.lbl.gov (ita.ee.lbl.gov)|131.243.2.164|:21... connected.\nLogging in as anonymous ...\nLogin incorrect.\nmv: rename ./clarknet_access_log_Sep4.gz to ./data/clarknet_access_log_Sep4.gz: No such file or directory\n"
    }
   ],
   "source": [
    "path_to_data_dir = \"./data/\"\n",
    "if not os.path.exists(path_to_data_dir):\n",
    "    os.mkdir(path_to_data_dir)\n",
    "    print(\"Created data directory\")\n",
    "\n",
    "if not os.path.exists(\"./data/NASA_access_log_Jul95.gz\"):\n",
    "    !wget ftp://ita.ee.lbl.gov/traces/NASA_access_log_Jul95.gz \n",
    "    !mv ./NASA_access_log_Jul95.gz ./data/\n",
    "\n",
    "if not os.path.exists(\"./data/NASA_access_log_Aug95.gz\"):\n",
    "    !wget ftp://ita.ee.lbl.gov/traces/NASA_access_log_Aug95.gz \n",
    "    !mv ./NASA_access_log_Aug95.gz ./data/\n",
    "\n",
    "if not os.path.exists(\"./data/clarknet_access_log_Aug28.gz\"):\n",
    "    !wget ftp://ita.ee.lbl.gov/traces/clarknet_access_log_Aug28.gz \n",
    "    !mv ./clarknet_access_log_Aug28.gz ./data/\n",
    "\n",
    "if not os.path.exists(\"./data/clarknet_access_log_Sep4.gz\"):\n",
    "    !wget ftp://ita.ee.lbl.gov/traces/clarknet_access_log_Sep4.gz\n",
    "    !mv ./clarknet_access_log_Sep4.gz ./data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Nasa Log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['./data/NASA_access_log_Jul95.gz', './data/NASA_access_log_Aug95.gz']"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "raw_data_files = glob.glob('./data/*.gz')\n",
    "raw_data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "root\n |-- value: string (nullable = true)\n\n"
    }
   ],
   "source": [
    "base_df = spark.read.text(raw_data_files)\n",
    "base_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "pyspark.sql.dataframe.DataFrame"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "type(base_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/opt/spark-2.4.5-bin-hadoop2.7\n/Users/rojan/Kathmandu/CodeSpace/Github/SparkTutorial/pyspark_venv/bin:/usr/local/bin:/usr/bin:/Users/rojan/anaconda3/bin:/Users/rojan/anaconda3/condabin:/Users/rojan/.rvm/gems/ruby-2.6.1/bin:/Users/rojan/.rvm/gems/ruby-2.6.1@global/bin:/Users/rojan/.rvm/rubies/ruby-2.6.1/bin:/opt/spark-2.4.5-bin-hadoop2.7/bin:/Users/rojan/.gem/ruby/2.3.0/bin:/Users/rojan/Rojan/Work/Codes/nsSNP/scripts:/Users/rojan/Rojan/Work/AlbertEinstein/ProgramDevelopment/pphore:/Users/rojan/Rojan/Work/AlbertEinstein/ProgramDevelopment/pharmacophore2pdb:/Users/rojan/Rojan/Work/AlbertEinstein/ProgramDevelopment/compare_two_vectors_correl:/Users/rojan/Rojan/Work/AlbertEinstein/ProgramDevelopment/MDElapsedTime:/Users/rojan/Rojan/Work/AlbertEinstein/ProgramDevelopment/MDTrj:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/X11/bin:/Users/rojan/Kathmandu/Work/DataScience/softwares/bowtie2-2.3.4.3-macos-x86_64:/usr/local/Cellar/gcc/8.2.0/bin:/Users/rojan/.rvm/bin:/Users/rojan/Kathmandu/CodeSpace/Github/MedicalChat/serving:/usr/local/Cellar/gcc/8.2.0/bin\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "pyspark.rdd.RDD"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "os.environ[\"SPARK_HOME\"] = \"/opt/spark-2.4.5-bin-hadoop2.7\"\n",
    "#os.environ[\"PYSPARK_PYTHON\"]=\"/usr/local/bin/python3\"\n",
    "print(os.environ.get('SPARK_HOME'))\n",
    "print(os.environ.get('PATH'))\n",
    "base_df_rdd = base_df.rdd\n",
    "type(base_df_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+-------------------------------------------------------------------------------------------------+\n|value                                                                                            |\n+-------------------------------------------------------------------------------------------------+\n|199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245           |\n|unicomp6.unicomp.net - - [01/Jul/1995:00:00:06 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985|\n+-------------------------------------------------------------------------------------------------+\nonly showing top 2 rows\n\n"
    }
   ],
   "source": [
    "base_df.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install findspark\n",
    "# os.environ.get('SPARK_HOME')\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[Row(value='199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245'),\n Row(value='unicomp6.unicomp.net - - [01/Jul/1995:00:00:06 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985')]"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "base_df_rdd.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245',\n 'unicomp6.unicomp.net - - [01/Jul/1995:00:00:06 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985']"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "sample_logs = [item['value'] for item in base_df.take(2)]\n",
    "sample_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting host names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['199.72.81.55', 'unicomp6.unicomp.net']"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "host_pattern = r'(^\\S+\\.[\\S+\\.]+\\S+)\\s'\n",
    "hosts = [re.search(host_pattern, item).group(1)\n",
    "           if re.search(host_pattern, item)\n",
    "           else 'no match'\n",
    "           for item in sample_logs]\n",
    "hosts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['01/Jul/1995:00:00:01 -0400', '01/Jul/1995:00:00:06 -0400']"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "ts_pattern = r'\\[(\\d{2}/\\w{3}/\\d{4}:\\d{2}:\\d{2}:\\d{2} -\\d{4})]'\n",
    "timestamps = [re.search(ts_pattern, item).group(1) for item in sample_logs]\n",
    "timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting HTTP Request Method, URIs and Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('GET', '/history/apollo/', 'HTTP/1.0'),\n ('GET', '/shuttle/countdown/', 'HTTP/1.0')]"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "method_uri_protocol_pattern = r'\\\"(\\S+)\\s(\\S+)\\s*(\\S*)\\\"'\n",
    "method_uri_protocol = [re.search(method_uri_protocol_pattern, item).groups()\n",
    "               if re.search(method_uri_protocol_pattern, item)\n",
    "               else 'no match'\n",
    "              for item in sample_logs]\n",
    "method_uri_protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting HTTP Status Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['200', '200']"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "status_pattern = r'\\s(\\d{3})\\s'\n",
    "status = [re.search(status_pattern, item).group(1) for item in sample_logs]\n",
    "status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting HTTP Response Content Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['6245', '3985']\n"
    }
   ],
   "source": [
    "content_size_pattern = r'\\s(\\d+)$'\n",
    "content_size = [re.search(content_size_pattern, item).group(1) for item in sample_logs]\n",
    "print(content_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+--------------------+--------------------+------+-------------------+--------+------+------------+\n|                host|           timestamp|method|           endpoint|protocol|status|content_size|\n+--------------------+--------------------+------+-------------------+--------+------+------------+\n|        199.72.81.55|01/Jul/1995:00:00...|   GET|   /history/apollo/|HTTP/1.0|   200|        6245|\n|unicomp6.unicomp.net|01/Jul/1995:00:00...|   GET|/shuttle/countdown/|HTTP/1.0|   200|        3985|\n+--------------------+--------------------+------+-------------------+--------+------+------------+\nonly showing top 2 rows\n\n(<bound method DataFrame.count of DataFrame[host: string, timestamp: string, method: string, endpoint: string, protocol: string, status: int, content_size: int]>, 7)\n"
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "\n",
    "logs_df = base_df.select(regexp_extract('value', host_pattern, 1).alias('host'),\n",
    "                         regexp_extract('value', ts_pattern, 1).alias('timestamp'),\n",
    "                         regexp_extract('value', method_uri_protocol_pattern, 1).alias('method'),\n",
    "                         regexp_extract('value', method_uri_protocol_pattern, 2).alias('endpoint'),\n",
    "                         regexp_extract('value', method_uri_protocol_pattern, 3).alias('protocol'),\n",
    "                         regexp_extract('value', status_pattern, 1).cast('integer').alias('status'),\n",
    "                         regexp_extract('value', content_size_pattern, 1).cast('integer').alias('content_size'))\n",
    "logs_df.show(2, truncate=True)\n",
    "print((logs_df.count, len(logs_df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DataFrame[value: string]"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "base_df.filter(base_df['value'].isNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_rows_df = logs_df.filter(logs_df['host'].isNull()| \n",
    "                             logs_df['timestamp'].isNull() | \n",
    "                             logs_df['method'].isNull() |\n",
    "                             logs_df['endpoint'].isNull() |\n",
    "                             logs_df['status'].isNull() |\n",
    "                             logs_df['content_size'].isNull()|\n",
    "                             logs_df['protocol'].isNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+--------------------+--------------------+------+--------------------+--------+------+------------+\n|                host|           timestamp|method|            endpoint|protocol|status|content_size|\n+--------------------+--------------------+------+--------------------+--------+------+------------+\n|dd15-062.compuser...|01/Jul/1995:00:01...|   GET|/news/sci.space.s...|HTTP/1.0|   404|        null|\n|     dynip42.efn.org|01/Jul/1995:00:02...|   GET|           /software|HTTP/1.0|   302|        null|\n+--------------------+--------------------+------+--------------------+--------+------+------------+\nonly showing top 2 rows\n\n"
    }
   ],
   "source": [
    "bad_rows_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['host',\n 'timestamp',\n 'method',\n 'endpoint',\n 'protocol',\n 'status',\n 'content_size']"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "bad_rows_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----+---------+------+--------+--------+------+------------+\n|host|timestamp|method|endpoint|protocol|status|content_size|\n+----+---------+------+--------+--------+------+------------+\n|   0|        0|     0|       0|       0|     1|       33905|\n+----+---------+------+--------+--------+------+------------+\n\n"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import sum as spark_sum\n",
    "\n",
    "def count_null(col_name):\n",
    "    return spark_sum(col(col_name).isNull().cast('integer')).alias(col_name)\n",
    "\n",
    "# Build up a list of column expressions, one per column.\n",
    "exprs = [count_null(col_name) for col_name in logs_df.columns]\n",
    "\n",
    "# Run the aggregation. The *exprs converts the list of expressions into\n",
    "# variable function arguments.\n",
    "logs_df.agg(*exprs).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+--------+\n|   value|\n+--------+\n|alyssa.p|\n+--------+\n\n"
    }
   ],
   "source": [
    "null_status_df = base_df.filter(~base_df['value'].rlike(r'\\s(\\d{3})\\s'))\n",
    "null_status_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----+---------+------+--------+--------+------+------------+\n|host|timestamp|method|endpoint|protocol|status|content_size|\n+----+---------+------+--------+--------+------+------------+\n|    |         |      |        |        |null  |null        |\n+----+---------+------+--------+--------+------+------------+\n\n"
    }
   ],
   "source": [
    "bad_status_df = null_status_df.select(regexp_extract('value', host_pattern, 1).alias('host'),\n",
    "                                      regexp_extract('value', ts_pattern, 1).alias('timestamp'),\n",
    "                                      regexp_extract('value', method_uri_protocol_pattern, 1).alias('method'),\n",
    "                                      regexp_extract('value', method_uri_protocol_pattern, 2).alias('endpoint'),\n",
    "                                      regexp_extract('value', method_uri_protocol_pattern, 3).alias('protocol'),\n",
    "                                      regexp_extract('value', status_pattern, 1).cast('integer').alias('status'),\n",
    "                                      regexp_extract('value', content_size_pattern, 1).cast('integer').alias('content_size'))\n",
    "bad_status_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----+---------+------+--------+--------+------+------------+\n|host|timestamp|method|endpoint|protocol|status|content_size|\n+----+---------+------+--------+--------+------+------------+\n|    |         |      |        |        |  null|        null|\n+----+---------+------+--------+--------+------+------------+\n\n"
    }
   ],
   "source": [
    "bad_status_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+--------------------+--------------------+------+-------------------+--------+------+------------+\n|                host|           timestamp|method|           endpoint|protocol|status|content_size|\n+--------------------+--------------------+------+-------------------+--------+------+------------+\n|        199.72.81.55|01/Jul/1995:00:00...|   GET|   /history/apollo/|HTTP/1.0|   200|        6245|\n|unicomp6.unicomp.net|01/Jul/1995:00:00...|   GET|/shuttle/countdown/|HTTP/1.0|   200|        3985|\n+--------------------+--------------------+------+-------------------+--------+------+------------+\nonly showing top 2 rows\n\n"
    }
   ],
   "source": [
    "logs_df.show(2)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+--------------------+--------------------+------+--------------------+--------+------+------------+\n|                host|           timestamp|method|            endpoint|protocol|status|content_size|\n+--------------------+--------------------+------+--------------------+--------+------+------------+\n|        199.72.81.55|01/Jul/1995:00:00...|   GET|    /history/apollo/|HTTP/1.0|   200|        6245|\n|unicomp6.unicomp.net|01/Jul/1995:00:00...|   GET| /shuttle/countdown/|HTTP/1.0|   200|        3985|\n|      199.120.110.21|01/Jul/1995:00:00...|   GET|/shuttle/missions...|HTTP/1.0|   200|        4085|\n|  burger.letters.com|01/Jul/1995:00:00...|   GET|/shuttle/countdow...|HTTP/1.0|   304|           0|\n|      199.120.110.21|01/Jul/1995:00:00...|   GET|/shuttle/missions...|HTTP/1.0|   200|        4179|\n|  burger.letters.com|01/Jul/1995:00:00...|   GET|/images/NASA-logo...|HTTP/1.0|   304|           0|\n|  burger.letters.com|01/Jul/1995:00:00...|   GET|/shuttle/countdow...|HTTP/1.0|   200|           0|\n|     205.212.115.106|01/Jul/1995:00:00...|   GET|/shuttle/countdow...|HTTP/1.0|   200|        3985|\n|         d104.aa.net|01/Jul/1995:00:00...|   GET| /shuttle/countdown/|HTTP/1.0|   200|        3985|\n|      129.94.144.152|01/Jul/1995:00:00...|   GET|                   /|HTTP/1.0|   200|        7074|\n+--------------------+--------------------+------+--------------------+--------+------+------------+\nonly showing top 10 rows\n\n"
    }
   ],
   "source": [
    "logs_df = logs_df[logs_df['status'].isNotNull()]\n",
    "logs_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----+---------+------+--------+--------+------+------------+\n|host|timestamp|method|endpoint|protocol|status|content_size|\n+----+---------+------+--------+--------+------+------------+\n|   0|        0|     0|       0|       0|     0|       33904|\n+----+---------+------+--------+--------+------+------------+\n\n"
    }
   ],
   "source": [
    "exprs = [count_null(col_name) for col_name in logs_df.columns]\n",
    "logs_df.agg(*exprs).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling nulls in HTTP content size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+--------------------+\n|               value|\n+--------------------+\n|dd15-062.compuser...|\n+--------------------+\nonly showing top 1 row\n\n"
    }
   ],
   "source": [
    "null_content_size_df = base_df.filter(~base_df['value'].rlike(r'\\s\\d+$'))\n",
    "null_content_size_df.show(1, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[Row(value='dd15-062.compuserve.com - - [01/Jul/1995:00:01:12 -0400] \"GET /news/sci.space.shuttle/archive/sci-space-shuttle-22-apr-1995-40.txt HTTP/1.0\" 404 -'),\n Row(value='dynip42.efn.org - - [01/Jul/1995:00:02:14 -0400] \"GET /software HTTP/1.0\" 302 -')]"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "null_content_size_df.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_df = logs_df.na.fill({'content_size': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----+---------+------+--------+--------+------+------------+\n|host|timestamp|method|endpoint|protocol|status|content_size|\n+----+---------+------+--------+--------+------+------------+\n|   0|        0|     0|       0|       0|     0|           0|\n+----+---------+------+--------+--------+------+------------+\n\n"
    }
   ],
   "source": [
    "exprs = [count_null(col_name) for col_name in logs_df.columns]\n",
    "logs_df.agg(*exprs).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Temporal Fields (Timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import TimestampType\n",
    "from datetime import datetime\n",
    "\n",
    "month_str_ints = {'Jan': 1, 'Feb': 2, 'Mar':3, 'Apr':4 , 'May': 5, 'Jun':6, \n",
    "             'Jul': 7, 'Aug': 8, 'Sep':9, 'Oct':10, 'Nov':11, 'Dec':12 }\n",
    "\n",
    "def parse_clf_time(text):\n",
    "    print(text)\n",
    "    # NOTE: We're ignoring the time zones here, might need to be handled depending on the problem you are solving\n",
    "\n",
    "    # datetime.strptime(datetime_str, '%m/%d/%y %H:%M:%S')\n",
    "    \n",
    "    a = \"{0:04d}/{1:02d}/{2:02d} {3:02d}:{4:02d}:{5:02d}\".format(\n",
    "      int(text[7:11]),\n",
    "      month_str_ints[text[3:6]],\n",
    "      int(text[0:2]),\n",
    "      int(text[12:14]),\n",
    "      int(text[15:17]),\n",
    "      int(text[18:20]))\n",
    "    return a\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "root\n |-- host: string (nullable = true)\n |-- timestamp: string (nullable = true)\n |-- method: string (nullable = true)\n |-- endpoint: string (nullable = true)\n |-- protocol: string (nullable = true)\n |-- status: integer (nullable = true)\n |-- content_size: integer (nullable = false)\n\n"
    }
   ],
   "source": [
    "logs_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['199.72.81.55', 'unicomp6.unicomp.net']"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "sample_ts = [item['host'] for item in logs_df.select('host').take(2)]\n",
    "sample_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['01/Jul/1995:00:00:01 -0400', '01/Jul/1995:00:00:06 -0400']"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "sample_ts = [item['timestamp'] for item in logs_df.select('timestamp').take(2)]\n",
    "sample_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = logs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "01/Jul/1995:00:00:01 -0400\n01/Jul/1995:00:00:06 -0400\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['1995/07/01 00:00:01', '1995/07/01 00:00:06']"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "[parse_clf_time(item) for item in sample_ts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+--------------------+--------------------+------+-------------------+--------+------+------------+\n|                host|           timestamp|method|           endpoint|protocol|status|content_size|\n+--------------------+--------------------+------+-------------------+--------+------+------------+\n|        199.72.81.55|01/Jul/1995:00:00...|   GET|   /history/apollo/|HTTP/1.0|   200|        6245|\n|unicomp6.unicomp.net|01/Jul/1995:00:00...|   GET|/shuttle/countdown/|HTTP/1.0|   200|        3985|\n+--------------------+--------------------+------+-------------------+--------+------+------------+\nonly showing top 2 rows\n\n"
    }
   ],
   "source": [
    "logs_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "root\n |-- host: string (nullable = true)\n |-- timestamp: string (nullable = true)\n |-- method: string (nullable = true)\n |-- endpoint: string (nullable = true)\n |-- protocol: string (nullable = true)\n |-- status: integer (nullable = true)\n |-- content_size: integer (nullable = false)\n\n"
    }
   ],
   "source": [
    "logs_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import unix_timestamp\n",
    "udf_parse_time = udf(parse_clf_time)\n",
    "a = logs_df.select('*', unix_timestamp(udf_parse_time(logs_df['timestamp']), \"yyyy/MM/dd HH:mm:ss\")\n",
    "                                .cast(TimestampType())\n",
    "                                .alias('time')).drop('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+--------------------+------+--------------------+--------+------+------------+-------------------+\n|                host|method|            endpoint|protocol|status|content_size|               time|\n+--------------------+------+--------------------+--------+------+------------+-------------------+\n|        199.72.81.55|   GET|    /history/apollo/|HTTP/1.0|   200|        6245|1995-07-01 00:00:01|\n|unicomp6.unicomp.net|   GET| /shuttle/countdown/|HTTP/1.0|   200|        3985|1995-07-01 00:00:06|\n|      199.120.110.21|   GET|/shuttle/missions...|HTTP/1.0|   200|        4085|1995-07-01 00:00:09|\n|  burger.letters.com|   GET|/shuttle/countdow...|HTTP/1.0|   304|           0|1995-07-01 00:00:11|\n|      199.120.110.21|   GET|/shuttle/missions...|HTTP/1.0|   200|        4179|1995-07-01 00:00:11|\n|  burger.letters.com|   GET|/images/NASA-logo...|HTTP/1.0|   304|           0|1995-07-01 00:00:12|\n|  burger.letters.com|   GET|/shuttle/countdow...|HTTP/1.0|   200|           0|1995-07-01 00:00:12|\n|     205.212.115.106|   GET|/shuttle/countdow...|HTTP/1.0|   200|        3985|1995-07-01 00:00:12|\n|         d104.aa.net|   GET| /shuttle/countdown/|HTTP/1.0|   200|        3985|1995-07-01 00:00:13|\n|      129.94.144.152|   GET|                   /|HTTP/1.0|   200|        7074|1995-07-01 00:00:13|\n|unicomp6.unicomp.net|   GET|/shuttle/countdow...|HTTP/1.0|   200|       40310|1995-07-01 00:00:14|\n|unicomp6.unicomp.net|   GET|/images/NASA-logo...|HTTP/1.0|   200|         786|1995-07-01 00:00:14|\n|unicomp6.unicomp.net|   GET|/images/KSC-logos...|HTTP/1.0|   200|        1204|1995-07-01 00:00:14|\n|         d104.aa.net|   GET|/shuttle/countdow...|HTTP/1.0|   200|       40310|1995-07-01 00:00:15|\n|         d104.aa.net|   GET|/images/NASA-logo...|HTTP/1.0|   200|         786|1995-07-01 00:00:15|\n|         d104.aa.net|   GET|/images/KSC-logos...|HTTP/1.0|   200|        1204|1995-07-01 00:00:15|\n|      129.94.144.152|   GET|/images/ksclogo-m...|HTTP/1.0|   304|           0|1995-07-01 00:00:17|\n|      199.120.110.21|   GET|/images/launch-lo...|HTTP/1.0|   200|        1713|1995-07-01 00:00:17|\n|ppptky391.asahi-n...|   GET|/facts/about_ksc....|HTTP/1.0|   200|        3977|1995-07-01 00:00:18|\n|  net-1-141.eden.com|   GET|/shuttle/missions...|HTTP/1.0|   200|       34029|1995-07-01 00:00:19|\n+--------------------+------+--------------------+--------+------+------------+-------------------+\nonly showing top 20 rows\n\n"
    }
   ],
   "source": [
    "a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+--------------------+--------------------+------+--------------------+--------+------+------------+\n|                host|           timestamp|method|            endpoint|protocol|status|content_size|\n+--------------------+--------------------+------+--------------------+--------+------+------------+\n|        199.72.81.55|01/Jul/1995:00:00...|   GET|    /history/apollo/|HTTP/1.0|   200|        6245|\n|unicomp6.unicomp.net|01/Jul/1995:00:00...|   GET| /shuttle/countdown/|HTTP/1.0|   200|        3985|\n|      199.120.110.21|01/Jul/1995:00:00...|   GET|/shuttle/missions...|HTTP/1.0|   200|        4085|\n|  burger.letters.com|01/Jul/1995:00:00...|   GET|/shuttle/countdow...|HTTP/1.0|   304|           0|\n|      199.120.110.21|01/Jul/1995:00:00...|   GET|/shuttle/missions...|HTTP/1.0|   200|        4179|\n|  burger.letters.com|01/Jul/1995:00:00...|   GET|/images/NASA-logo...|HTTP/1.0|   304|           0|\n|  burger.letters.com|01/Jul/1995:00:00...|   GET|/shuttle/countdow...|HTTP/1.0|   200|           0|\n|     205.212.115.106|01/Jul/1995:00:00...|   GET|/shuttle/countdow...|HTTP/1.0|   200|        3985|\n|         d104.aa.net|01/Jul/1995:00:00...|   GET| /shuttle/countdown/|HTTP/1.0|   200|        3985|\n|      129.94.144.152|01/Jul/1995:00:00...|   GET|                   /|HTTP/1.0|   200|        7074|\n|unicomp6.unicomp.net|01/Jul/1995:00:00...|   GET|/shuttle/countdow...|HTTP/1.0|   200|       40310|\n|unicomp6.unicomp.net|01/Jul/1995:00:00...|   GET|/images/NASA-logo...|HTTP/1.0|   200|         786|\n|unicomp6.unicomp.net|01/Jul/1995:00:00...|   GET|/images/KSC-logos...|HTTP/1.0|   200|        1204|\n|         d104.aa.net|01/Jul/1995:00:00...|   GET|/shuttle/countdow...|HTTP/1.0|   200|       40310|\n|         d104.aa.net|01/Jul/1995:00:00...|   GET|/images/NASA-logo...|HTTP/1.0|   200|         786|\n|         d104.aa.net|01/Jul/1995:00:00...|   GET|/images/KSC-logos...|HTTP/1.0|   200|        1204|\n|      129.94.144.152|01/Jul/1995:00:00...|   GET|/images/ksclogo-m...|HTTP/1.0|   304|           0|\n|      199.120.110.21|01/Jul/1995:00:00...|   GET|/images/launch-lo...|HTTP/1.0|   200|        1713|\n|ppptky391.asahi-n...|01/Jul/1995:00:00...|   GET|/facts/about_ksc....|HTTP/1.0|   200|        3977|\n|  net-1-141.eden.com|01/Jul/1995:00:00...|   GET|/shuttle/missions...|HTTP/1.0|   200|       34029|\n+--------------------+--------------------+------+--------------------+--------+------+------------+\nonly showing top 20 rows\n\n"
    }
   ],
   "source": [
    "logs_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "root\n |-- host: string (nullable = true)\n |-- method: string (nullable = true)\n |-- endpoint: string (nullable = true)\n |-- protocol: string (nullable = true)\n |-- status: integer (nullable = true)\n |-- content_size: integer (nullable = false)\n |-- time: timestamp (nullable = true)\n\n"
    }
   ],
   "source": [
    "a.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+--------------------+------+--------------------+--------+------+------------+-------------------+\n|                host|method|            endpoint|protocol|status|content_size|               time|\n+--------------------+------+--------------------+--------+------+------------+-------------------+\n|        199.72.81.55|   GET|    /history/apollo/|HTTP/1.0|   200|        6245|1995-07-01 00:00:01|\n|unicomp6.unicomp.net|   GET| /shuttle/countdown/|HTTP/1.0|   200|        3985|1995-07-01 00:00:06|\n|      199.120.110.21|   GET|/shuttle/missions...|HTTP/1.0|   200|        4085|1995-07-01 00:00:09|\n|  burger.letters.com|   GET|/shuttle/countdow...|HTTP/1.0|   304|           0|1995-07-01 00:00:11|\n|      199.120.110.21|   GET|/shuttle/missions...|HTTP/1.0|   200|        4179|1995-07-01 00:00:11|\n|  burger.letters.com|   GET|/images/NASA-logo...|HTTP/1.0|   304|           0|1995-07-01 00:00:12|\n|  burger.letters.com|   GET|/shuttle/countdow...|HTTP/1.0|   200|           0|1995-07-01 00:00:12|\n|     205.212.115.106|   GET|/shuttle/countdow...|HTTP/1.0|   200|        3985|1995-07-01 00:00:12|\n|         d104.aa.net|   GET| /shuttle/countdown/|HTTP/1.0|   200|        3985|1995-07-01 00:00:13|\n|      129.94.144.152|   GET|                   /|HTTP/1.0|   200|        7074|1995-07-01 00:00:13|\n|unicomp6.unicomp.net|   GET|/shuttle/countdow...|HTTP/1.0|   200|       40310|1995-07-01 00:00:14|\n|unicomp6.unicomp.net|   GET|/images/NASA-logo...|HTTP/1.0|   200|         786|1995-07-01 00:00:14|\n|unicomp6.unicomp.net|   GET|/images/KSC-logos...|HTTP/1.0|   200|        1204|1995-07-01 00:00:14|\n|         d104.aa.net|   GET|/shuttle/countdow...|HTTP/1.0|   200|       40310|1995-07-01 00:00:15|\n|         d104.aa.net|   GET|/images/NASA-logo...|HTTP/1.0|   200|         786|1995-07-01 00:00:15|\n|         d104.aa.net|   GET|/images/KSC-logos...|HTTP/1.0|   200|        1204|1995-07-01 00:00:15|\n|      129.94.144.152|   GET|/images/ksclogo-m...|HTTP/1.0|   304|           0|1995-07-01 00:00:17|\n|      199.120.110.21|   GET|/images/launch-lo...|HTTP/1.0|   200|        1713|1995-07-01 00:00:17|\n|ppptky391.asahi-n...|   GET|/facts/about_ksc....|HTTP/1.0|   200|        3977|1995-07-01 00:00:18|\n|  net-1-141.eden.com|   GET|/shuttle/missions...|HTTP/1.0|   200|       34029|1995-07-01 00:00:19|\n+--------------------+------+--------------------+--------+------+------------+-------------------+\nonly showing top 20 rows\n\n"
    }
   ],
   "source": [
    "a.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explortory Data Analysis (EDA)\n",
    "\n",
    "## HTTP Status\n",
    "First, unique HTTP status is determined and then find their distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_freq = (logs_df\n",
    "                     .groupBy('status')\n",
    "                     .count()\n",
    "                     .sort('status')\n",
    "                     .cache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   status    count   percent  log(count)\n0     200  3100524  0.895688   14.947082\n2     304   266773  0.077066   12.494153\n1     302    73070  0.021109   11.199173\n5     404    20899  0.006037    9.947457\n4     403      225  0.000065    5.416100\n6     500       65  0.000019    4.174387\n7     501       41  0.000012    3.713572\n3     400       15  0.000004    2.708050",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>status</th>\n      <th>count</th>\n      <th>percent</th>\n      <th>log(count)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>200</td>\n      <td>3100524</td>\n      <td>0.895688</td>\n      <td>14.947082</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>304</td>\n      <td>266773</td>\n      <td>0.077066</td>\n      <td>12.494153</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>302</td>\n      <td>73070</td>\n      <td>0.021109</td>\n      <td>11.199173</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>404</td>\n      <td>20899</td>\n      <td>0.006037</td>\n      <td>9.947457</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>403</td>\n      <td>225</td>\n      <td>0.000065</td>\n      <td>5.416100</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>500</td>\n      <td>65</td>\n      <td>0.000019</td>\n      <td>4.174387</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>501</td>\n      <td>41</td>\n      <td>0.000012</td>\n      <td>3.713572</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>400</td>\n      <td>15</td>\n      <td>0.000004</td>\n      <td>2.708050</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "df_pd_status_freq = (df_status_freq\n",
    "                         .toPandas()\n",
    "                         .sort_values(by=['count'], ascending=False))\n",
    "\n",
    "df_pd_status_freq['percent'] = df_pd_status_freq['count']/sum(df_pd_status_freq['count'])\n",
    "df_pd_status_freq['log(count)'] = np.log(df_pd_status_freq['count'])\n",
    "df_pd_status_freq\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   status    count   percent\n0     200  3100524  0.895688\n2     304   266773  0.077066\n1     302    73070  0.021109\n5     404    20899  0.006037\n4     403      225  0.000065",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>status</th>\n      <th>count</th>\n      <th>percent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>200</td>\n      <td>3100524</td>\n      <td>0.895688</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>304</td>\n      <td>266773</td>\n      <td>0.077066</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>302</td>\n      <td>73070</td>\n      <td>0.021109</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>404</td>\n      <td>20899</td>\n      <td>0.006037</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>403</td>\n      <td>225</td>\n      <td>0.000065</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "df_pd_status_freq.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequent host\n",
    "\n",
    "Identify the top ten host and also compute their proportion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+--------------------+--------------------+------+-------------------+--------+------+------------+\n|                host|           timestamp|method|           endpoint|protocol|status|content_size|\n+--------------------+--------------------+------+-------------------+--------+------+------------+\n|        199.72.81.55|01/Jul/1995:00:00...|   GET|   /history/apollo/|HTTP/1.0|   200|        6245|\n|unicomp6.unicomp.net|01/Jul/1995:00:00...|   GET|/shuttle/countdown/|HTTP/1.0|   200|        3985|\n+--------------------+--------------------+------+-------------------+--------+------+------------+\nonly showing top 2 rows\n\n"
    }
   ],
   "source": [
    "logs_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_host_freq = (logs_df\n",
    "                     .groupBy('host')\n",
    "                     .count()\n",
    "                     .cache())\n",
    "df_pd_host_freq = (df_host_freq\n",
    "                        .toPandas()\n",
    "                        .sort_values(by=['count'], ascending=False))\n",
    "df_pd_host_freq[\"Percentage\"] = df_pd_host_freq[\"count\"] / sum(df_pd_host_freq[\"count\"])\n",
    "df_pd_host_freq[\"Log(count)\"] = np.log(df_pd_host_freq[\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                        host  count  Percentage  Log(count)\n116548  piweba3y.prodigy.com  21988    0.006352    9.998252\n124250  piweba4y.prodigy.com  16437    0.004748    9.707290\n40617   piweba1y.prodigy.com  12825    0.003705    9.459152",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>host</th>\n      <th>count</th>\n      <th>Percentage</th>\n      <th>Log(count)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>116548</th>\n      <td>piweba3y.prodigy.com</td>\n      <td>21988</td>\n      <td>0.006352</td>\n      <td>9.998252</td>\n    </tr>\n    <tr>\n      <th>124250</th>\n      <td>piweba4y.prodigy.com</td>\n      <td>16437</td>\n      <td>0.004748</td>\n      <td>9.707290</td>\n    </tr>\n    <tr>\n      <th>40617</th>\n      <td>piweba1y.prodigy.com</td>\n      <td>12825</td>\n      <td>0.003705</td>\n      <td>9.459152</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "df_pd_host_freq.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                        host  count  Percentage  Log(count)      zscore\n116548  piweba3y.prodigy.com  21988    0.006352    9.998252  144.486587\n124250  piweba4y.prodigy.com  16437    0.004748    9.707290  107.968417\n40617   piweba1y.prodigy.com  12825    0.003705    9.459152   84.206279\n87525     edams.ksc.nasa.gov  11964    0.003456    9.389657   78.542048\n52461           163.206.89.4   9697    0.002801    9.179572   63.628215",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>host</th>\n      <th>count</th>\n      <th>Percentage</th>\n      <th>Log(count)</th>\n      <th>zscore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>116548</th>\n      <td>piweba3y.prodigy.com</td>\n      <td>21988</td>\n      <td>0.006352</td>\n      <td>9.998252</td>\n      <td>144.486587</td>\n    </tr>\n    <tr>\n      <th>124250</th>\n      <td>piweba4y.prodigy.com</td>\n      <td>16437</td>\n      <td>0.004748</td>\n      <td>9.707290</td>\n      <td>107.968417</td>\n    </tr>\n    <tr>\n      <th>40617</th>\n      <td>piweba1y.prodigy.com</td>\n      <td>12825</td>\n      <td>0.003705</td>\n      <td>9.459152</td>\n      <td>84.206279</td>\n    </tr>\n    <tr>\n      <th>87525</th>\n      <td>edams.ksc.nasa.gov</td>\n      <td>11964</td>\n      <td>0.003456</td>\n      <td>9.389657</td>\n      <td>78.542048</td>\n    </tr>\n    <tr>\n      <th>52461</th>\n      <td>163.206.89.4</td>\n      <td>9697</td>\n      <td>0.002801</td>\n      <td>9.179572</td>\n      <td>63.628215</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "mean    = np.mean(df_pd_host_freq['count'])\n",
    "std     = np.std(df_pd_host_freq['count'])\n",
    "df_pd_host_freq['zscore'] = (df_pd_host_freq['count'] - mean)/std\n",
    "df_pd_host_freq.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What method is most frequently used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_method = (logs_df\n",
    "                     .groupBy('method')\n",
    "                     .count()\n",
    "                     .cache())\n",
    "df_pd_method = (df_method\n",
    "                        .toPandas()\n",
    "                        .sort_values(by=['count'], ascending=False))\n",
    "df_pd_method[\"Percentage\"] = 100.00 * (df_pd_method[\"count\"] / sum(df_pd_method[\"count\"]))\n",
    "df_pd_method[\"Log(count)\"] = np.log(df_pd_method[\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            method    count  Percentage  Log(count)\n3              GET  3451720   99.714237   15.054383\n2             HEAD     7915    0.228651    8.976515\n4                      1753    0.050641    7.469084\n0             POST      222    0.006413    5.402677\n1  �|\u0005\u0011t\u0003�9ð'À|\u0005\u0011u        2    0.000058    0.693147",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>method</th>\n      <th>count</th>\n      <th>Percentage</th>\n      <th>Log(count)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>GET</td>\n      <td>3451720</td>\n      <td>99.714237</td>\n      <td>15.054383</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HEAD</td>\n      <td>7915</td>\n      <td>0.228651</td>\n      <td>8.976515</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>1753</td>\n      <td>0.050641</td>\n      <td>7.469084</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>POST</td>\n      <td>222</td>\n      <td>0.006413</td>\n      <td>5.402677</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>�|\u0005\u0011t\u0003�9ð'À|\u0005\u0011u</td>\n      <td>2</td>\n      <td>0.000058</td>\n      <td>0.693147</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "df_pd_method.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most popular method is GET followed by HEAD. However, 99% of times GET method is used. Superisingly, POST method is almost never used.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_protocol = (logs_df\n",
    "                     .groupBy('protocol')\n",
    "                     .count()\n",
    "                     .cache())\n",
    "df_protocol = (df_protocol\n",
    "                        .toPandas()\n",
    "                        .sort_values(by=['count'], ascending=False))\n",
    "df_protocol[\"Percentage\"] = 100.00 * (df_protocol[\"count\"] / sum(df_protocol[\"count\"]))\n",
    "df_protocol[\"Log(count)\"] = np.log(df_protocol[\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        protocol    count  Percentage  Log(count)\n4       HTTP/1.0  3454716   99.800786   15.055251\n2                    6599    0.190634    8.794673\n3      HTTP/V1.0      279    0.008060    5.631212\n0         HTTP/*       13    0.000376    2.564949\n5  STS-69</a><p>        4    0.000116    1.386294",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>protocol</th>\n      <th>count</th>\n      <th>Percentage</th>\n      <th>Log(count)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>HTTP/1.0</td>\n      <td>3454716</td>\n      <td>99.800786</td>\n      <td>15.055251</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>6599</td>\n      <td>0.190634</td>\n      <td>8.794673</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HTTP/V1.0</td>\n      <td>279</td>\n      <td>0.008060</td>\n      <td>5.631212</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>HTTP/*</td>\n      <td>13</td>\n      <td>0.000376</td>\n      <td>2.564949</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>STS-69&lt;/a&gt;&lt;p&gt;</td>\n      <td>4</td>\n      <td>0.000116</td>\n      <td>1.386294</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "df_protocol.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}